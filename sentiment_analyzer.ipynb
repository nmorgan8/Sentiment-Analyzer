{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3adbcffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.8.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n"
     ]
    }
   ],
   "source": [
    "# Run following commented section once to install if using as .ipynb\n",
    "# Ignore Otherwise\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install tensorflow\n",
    "# !{sys.executable} -m pip install tensorflow_hub\n",
    "# !{sys.executable} -m pip install tensorflow_datasets\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub # These imports will not work unless you've already installed them locally. Colab has them ready.\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "\n",
    "\n",
    "# Split the training set into 60% and 40% to end up with 15,000 examples\n",
    "# for training, 10,000 examples for validation and 25,000 examples for testing.\n",
    "train_data, validation_data, test_data = tfds.load(\n",
    "    name=\"imdb_reviews\", \n",
    "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
    "    as_supervised=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dce24ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all text data\n",
    "\n",
    "tokenizer_train = []\n",
    "train_label = []\n",
    "for idx, (sent, label) in enumerate(train_data):\n",
    "    sent = sent.numpy()\n",
    "    new_sent = [word for word in sent.lower().split()]\n",
    "    tokenizer_train.append(new_sent)\n",
    "    train_label.append([label.numpy()])\n",
    "\n",
    "tokenizer_valid = []\n",
    "valid_label = []\n",
    "for idx, (sent, label) in enumerate(validation_data):\n",
    "    sent = sent.numpy()\n",
    "    new_sent = [word for word in sent.lower().split()]  \n",
    "    tokenizer_valid.append(new_sent)\n",
    "    valid_label.append([label.numpy()])\n",
    "    \n",
    "tokenizer_test = []\n",
    "test_label = []\n",
    "for idx, (sent, label) in enumerate(test_data):\n",
    "    sent = sent.numpy()\n",
    "    new_sent = [word for word in sent.lower().split()]\n",
    "    tokenizer_test.append(new_sent)\n",
    "    test_label.append([label.numpy()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6027b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tokenizer_train)\n",
    "word_to_ix = tokenizer.word_index\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(tokenizer_train)\n",
    "max_len = max([len(x) for x in train_sequences])\n",
    "train_padded = pad_sequences(train_sequences, padding='post', truncating='post', maxlen=max_len)\n",
    "\n",
    "valid_sequences = tokenizer.texts_to_sequences(tokenizer_valid)\n",
    "valid_padded = pad_sequences(valid_sequences, padding='post', truncating='post', maxlen=max_len)\n",
    "\n",
    "test_sequences = tokenizer.texts_to_sequences(tokenizer_test)\n",
    "test_padded = pad_sequences(test_sequences, padding='post', truncating='post', maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f774429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 20:15:45.128221: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 46879488 exceeds 10% of free system memory.\n",
      "2022-04-27 20:15:45.200174: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 46879488 exceeds 10% of free system memory.\n",
      "2022-04-27 20:15:45.223710: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 46879488 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "                                    tf.keras.layers.Embedding(len(word_to_ix) + 1, 64, input_length=max_len),\n",
    "                                    tf.keras.layers.GlobalAveragePooling1D(),                                    \n",
    "                                    tf.keras.layers.Dense(10, activation='relu'),\n",
    "                                    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bce70b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 2470, 64)          11719872  \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 64)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                650       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,720,533\n",
      "Trainable params: 11,720,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56e110a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 20:16:31.714052: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 148200000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 20:16:32.521862: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 46879488 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 90s 190ms/step - loss: 0.6923 - accuracy: 0.5202 - val_loss: 0.6886 - val_accuracy: 0.5654\n",
      "Epoch 2/8\n",
      "469/469 [==============================] - 88s 188ms/step - loss: 0.6558 - accuracy: 0.6455 - val_loss: 0.6107 - val_accuracy: 0.6454\n",
      "Epoch 3/8\n",
      "469/469 [==============================] - 88s 188ms/step - loss: 0.5024 - accuracy: 0.8022 - val_loss: 0.4498 - val_accuracy: 0.8251\n",
      "Epoch 4/8\n",
      "469/469 [==============================] - 90s 191ms/step - loss: 0.3614 - accuracy: 0.8687 - val_loss: 0.3931 - val_accuracy: 0.8331\n",
      "Epoch 5/8\n",
      "469/469 [==============================] - 88s 187ms/step - loss: 0.2742 - accuracy: 0.9084 - val_loss: 0.3687 - val_accuracy: 0.8379\n",
      "Epoch 6/8\n",
      "469/469 [==============================] - 89s 189ms/step - loss: 0.2188 - accuracy: 0.9276 - val_loss: 0.3210 - val_accuracy: 0.8761\n",
      "Epoch 7/8\n",
      "469/469 [==============================] - 88s 188ms/step - loss: 0.1766 - accuracy: 0.9435 - val_loss: 0.3421 - val_accuracy: 0.8563\n",
      "Epoch 8/8\n",
      "469/469 [==============================] - 90s 191ms/step - loss: 0.1443 - accuracy: 0.9553 - val_loss: 0.3331 - val_accuracy: 0.8617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc10bcfde20>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label = np.array(train_label)\n",
    "valid_label = np.array(valid_label)\n",
    "test_label = np.array(test_label)\n",
    "\n",
    "model.fit(train_padded, train_label, epochs=8, validation_data=(valid_padded, valid_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38985700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 4s - loss: 0.3334 - accuracy: 0.8648 - 4s/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33343422412872314, 0.864799976348877]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_padded, test_label, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46496c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
